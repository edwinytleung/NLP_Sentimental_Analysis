{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layers with keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well use the imdb dataset to learn word embeddings as we train our dataset. This dataset contains 25,000 movie reviews from IMDB, labeled with sentiment (positive or negative). For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word. We will only use the first 20 words from each review to speed up training, use a max vocab size of 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edwin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "vocab_size = 10000 #vocab size\n",
    "maxlen = 20  #number of word used from each review\n",
    "#load dataset as a list of ints\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "#make all sequences of the same length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test =  pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'keras.datasets.imdb' from 'C:\\\\Users\\\\edwin\\\\Anaconda3\\\\lib\\\\site-packages\\\\keras\\\\datasets\\\\imdb.py'>\n"
     ]
    }
   ],
   "source": [
    "print(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape #number of review, number of words in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  65,   16,   38, ...,   19,  178,   32],\n",
       "       [  23,    4, 1690, ...,   16,  145,   95],\n",
       "       [1352,   13,  191, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [  11, 1818, 7561, ...,    4, 3586,    2],\n",
       "       [  92,  401,  728, ...,   12,    9,   23],\n",
       "       [ 764,   40,    4, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexiable and can be used in a few ways:\n",
    "\n",
    "* The embedding layer can be used at the start of a larger deep learning model. \n",
    "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
    "* Use the embedding layer to train our own word2vec models.\n",
    "\n",
    "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen)) #10000 for vocab size, 8 for dimensionality of embedding\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape #number of examples, number or words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  23,    4, 1690,   15,   16,    4, 1355,    5,   28,    6,   52,\n",
       "        154,  462,   33,   89,   78,  285,   16,  145,   95])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1] # words are representedby numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 11s 571us/step - loss: 0.6759 - acc: 0.6050 - val_loss: 0.6398 - val_acc: 0.6814\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 7s 371us/step - loss: 0.5657 - acc: 0.7427 - val_loss: 0.5467 - val_acc: 0.7206\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 7s 333us/step - loss: 0.4752 - acc: 0.7808 - val_loss: 0.5113 - val_acc: 0.7384\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 6s 316us/step - loss: 0.4263 - acc: 0.8077 - val_loss: 0.5008 - val_acc: 0.7452\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 7s 336us/step - loss: 0.3930 - acc: 0.8258 - val_loss: 0.4981 - val_acc: 0.7538\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 7s 330us/step - loss: 0.3668 - acc: 0.8395 - val_loss: 0.5014 - val_acc: 0.7530\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 7s 346us/step - loss: 0.3435 - acc: 0.8533 - val_loss: 0.5052 - val_acc: 0.7520\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 7s 349us/step - loss: 0.3223 - acc: 0.8657 - val_loss: 0.5132 - val_acc: 0.7486\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 7s 336us/step - loss: 0.3022 - acc: 0.8766 - val_loss: 0.5213 - val_acc: 0.7490\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 6s 303us/step - loss: 0.2839 - acc: 0.8860 - val_loss: 0.5303 - val_acc: 0.7466\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 6s 303us/step - loss: 0.2664 - acc: 0.8942 - val_loss: 0.5406 - val_acc: 0.7440ss: 0.2668 - a\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 7s 349us/step - loss: 0.2502 - acc: 0.9026 - val_loss: 0.5520 - val_acc: 0.7440\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 6s 309us/step - loss: 0.2346 - acc: 0.9089 - val_loss: 0.5654 - val_acc: 0.7420\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 8s 379us/step - loss: 0.2207 - acc: 0.9155 - val_loss: 0.5782 - val_acc: 0.7390\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 7s 335us/step - loss: 0.2073 - acc: 0.9202 - val_loss: 0.5928 - val_acc: 0.7380\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 7s 359us/step - loss: 0.1950 - acc: 0.9261 - val_loss: 0.6052 - val_acc: 0.7360\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 6s 323us/step - loss: 0.1838 - acc: 0.9313 - val_loss: 0.6209 - val_acc: 0.7332\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 7s 329us/step - loss: 0.1733 - acc: 0.9371 - val_loss: 0.6369 - val_acc: 0.7314\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 7s 346us/step - loss: 0.1634 - acc: 0.9408 - val_loss: 0.6521 - val_acc: 0.7278\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 5s 274us/step - loss: 0.1545 - acc: 0.9455 - val_loss: 0.6680 - val_acc: 0.7260\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "epochs=20,\n",
    "batch_size=32,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x1ac8385beb8>,\n",
       " <keras.layers.core.Flatten at 0x1ac8385bef0>,\n",
       " <keras.layers.core.Dense at 0x1ac8385c2b0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers #get all layers from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = model.layers[0].get_weights()[0] #get weights from embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the embedding layer corresponds to a word vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0].shape #10,000 words, 8D word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.shape #10000 words, embedings of shape 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2531628 , -0.01888705, -0.17107728, ...,  0.06188993,\n",
       "         0.11005876, -0.11686996],\n",
       "       [-0.0262525 ,  0.05628638, -0.12938961, ..., -0.22720085,\n",
       "         0.03819834,  0.11793949],\n",
       "       [-0.01901844, -0.06382567, -0.00030982, ...,  0.02522065,\n",
       "        -0.02231135, -0.025289  ],\n",
       "       ...,\n",
       "       [-0.03273454,  0.02918702, -0.04478579, ...,  0.16867042,\n",
       "        -0.01261579, -0.16748938],\n",
       "       [-0.17153065, -0.05938431, -0.01616969, ...,  0.03787478,\n",
       "        -0.00103477,  0.10654188],\n",
       "       [ 0.0136178 ,  0.06575242,  0.02363523, ...,  0.0191305 ,\n",
       "         0.07557042, -0.05249241]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Reuters newswire topics classification, the dataset contains 11,228 newswires from Reuters, labeled over 46 topics.   As with the IMDB dataset, each wire is encoded as a sequence of numbers.   \n",
    "\n",
    "You task is to create a neural network that can classify which topic the piece of text came from. Use an embedding layer to input the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ac9146e3c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac91182d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot([len(news) for news in x_train ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maxlen = 250  #number of word used from each review\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test =  pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 250)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "y = keras.utils.to_categorical(y_train)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 250, 8)            247768    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                92046     \n",
      "=================================================================\n",
      "Total params: 339,814\n",
      "Trainable params: 339,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(30971, 8, input_length=maxlen)) #10000 for vocab size, 8 for dimensionality of embedding\n",
    "model.add(Flatten())\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7185 samples, validate on 1797 samples\n",
      "Epoch 1/20\n",
      "7185/7185 [==============================] - 2s 277us/step - loss: 2.3681 - acc: 0.3620 - val_loss: 1.9923 - val_acc: 0.4619\n",
      "Epoch 2/20\n",
      "7185/7185 [==============================] - 2s 230us/step - loss: 1.8153 - acc: 0.4870 - val_loss: 1.7373 - val_acc: 0.5170\n",
      "Epoch 3/20\n",
      "7185/7185 [==============================] - 2s 246us/step - loss: 1.5665 - acc: 0.5776 - val_loss: 1.6083 - val_acc: 0.5893\n",
      "Epoch 4/20\n",
      "7185/7185 [==============================] - 2s 236us/step - loss: 1.3557 - acc: 0.6590 - val_loss: 1.5146 - val_acc: 0.6272\n",
      "Epoch 5/20\n",
      "7185/7185 [==============================] - 2s 231us/step - loss: 1.1468 - acc: 0.7184 - val_loss: 1.4683 - val_acc: 0.6516\n",
      "Epoch 6/20\n",
      "7185/7185 [==============================] - 2s 227us/step - loss: 0.9456 - acc: 0.7770 - val_loss: 1.4039 - val_acc: 0.6683\n",
      "Epoch 7/20\n",
      "7185/7185 [==============================] - 2s 230us/step - loss: 0.7618 - acc: 0.8356 - val_loss: 1.3828 - val_acc: 0.6795\n",
      "Epoch 8/20\n",
      "7185/7185 [==============================] - 2s 226us/step - loss: 0.6093 - acc: 0.8750 - val_loss: 1.3777 - val_acc: 0.6756\n",
      "Epoch 9/20\n",
      "7185/7185 [==============================] - 2s 247us/step - loss: 0.4852 - acc: 0.9009 - val_loss: 1.4093 - val_acc: 0.6728\n",
      "Epoch 10/20\n",
      "7185/7185 [==============================] - 2s 227us/step - loss: 0.3962 - acc: 0.9183 - val_loss: 1.4359 - val_acc: 0.6778\n",
      "Epoch 11/20\n",
      "7185/7185 [==============================] - 2s 212us/step - loss: 0.3280 - acc: 0.9328 - val_loss: 1.4675 - val_acc: 0.6722\n",
      "Epoch 12/20\n",
      "7185/7185 [==============================] - 2s 236us/step - loss: 0.2780 - acc: 0.9408 - val_loss: 1.5224 - val_acc: 0.6772\n",
      "Epoch 13/20\n",
      "7185/7185 [==============================] - 2s 251us/step - loss: 0.2399 - acc: 0.9450 - val_loss: 1.5578 - val_acc: 0.6733\n",
      "Epoch 14/20\n",
      "7185/7185 [==============================] - 2s 222us/step - loss: 0.2108 - acc: 0.9513 - val_loss: 1.6004 - val_acc: 0.6700\n",
      "Epoch 15/20\n",
      "7185/7185 [==============================] - 2s 216us/step - loss: 0.1841 - acc: 0.9552 - val_loss: 1.6357 - val_acc: 0.6694\n",
      "Epoch 16/20\n",
      "7185/7185 [==============================] - 1s 207us/step - loss: 0.1673 - acc: 0.9573 - val_loss: 1.6807 - val_acc: 0.6672\n",
      "Epoch 17/20\n",
      "7185/7185 [==============================] - 2s 214us/step - loss: 0.1514 - acc: 0.9592 - val_loss: 1.7126 - val_acc: 0.6622\n",
      "Epoch 18/20\n",
      "7185/7185 [==============================] - 2s 248us/step - loss: 0.1397 - acc: 0.9613 - val_loss: 1.7802 - val_acc: 0.6683\n",
      "Epoch 19/20\n",
      "7185/7185 [==============================] - 2s 217us/step - loss: 0.1292 - acc: 0.9613 - val_loss: 1.7992 - val_acc: 0.6611\n",
      "Epoch 20/20\n",
      "7185/7185 [==============================] - 2s 218us/step - loss: 0.1205 - acc: 0.9602 - val_loss: 1.8732 - val_acc: 0.6639\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y,\n",
    "epochs=20,\n",
    "batch_size=32,\n",
    "validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('my_model2.h5')  \n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model2.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
